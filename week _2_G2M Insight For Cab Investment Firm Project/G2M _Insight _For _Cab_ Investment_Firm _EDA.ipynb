{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week 2: G2M Insight For Cab Investment Firm EDA Project\n",
    "\n",
    "Name: William Ogweli Okomba\n",
    "\n",
    "Internship Batch: LISUM01\n",
    "\n",
    "Date: 20/06/2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Defining the Question\n",
    "\n",
    "**Dataset provided**\n",
    "\n",
    "1. The datsets: [link](https://github.com/DataGlacier/DataSets.git)\n",
    "2. us dataset: [ link](https://www.kaggle.com/benjaminhendler/usholidays)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data grossary\n",
    "\n",
    "###### Cab dataset\n",
    "\n",
    "* TransactionID: unique Transaction number of the trip.\n",
    "\n",
    "* Date of Travel: Date of when the trip happened.\n",
    "\n",
    "* Company: Yellow Cab or Pink Cab.\n",
    "\n",
    "* City: US cities where the two cabs operate.\n",
    "\n",
    "* KM Travelled: Kilometers travelled per trip.\n",
    "\n",
    "* Price Charged: Total price of the trip.\n",
    "\n",
    "* Cost of Trip: estimate cost of the trip.\n",
    "\n",
    "\n",
    "###### city dataset\n",
    "\n",
    "* City: US cities where the two cabs operate.\n",
    "* Population:city population.\n",
    "* Users: Total number of users in per city.\n",
    "\n",
    "###### Transaction dataset\n",
    "\n",
    "* TransactionID: unique  number of the trip.\n",
    "* CustomerID: unique customer Identification Number.\n",
    "* Payment_Mode: Card or Cash Payment in each trip.\n",
    "\n",
    "##### customer dataset\n",
    "\n",
    "* CustomerID: Customer Identification Number.\n",
    "* Gender: Male or Female.\n",
    "* Age: Customer age.\n",
    "* Income(USD/Month): Customer monthly earnings.\n",
    "\n",
    "##### Us holiday dataset\n",
    "\n",
    "* date - yyyy-mm-dd\n",
    "\n",
    "* holiday_name - String - Name of the holiday.\n",
    "1 Year Day,\n",
    "2 Martin Luther King Jr. Day,\n",
    "3. Day (Washingtons Birthday),\n",
    "3 Good Friday,\n",
    "4 Memorial Day,\n",
    "5 Independence Day,\n",
    "6 Labor Day,\n",
    "7 Columbus Day,\n",
    "8 Halloween,\n",
    "9 Veterans Day,\n",
    "10 Thanksgiving Day,\n",
    "11 Christmas Eve,\n",
    "12 Christmas Day,\n",
    "13 New Year\n",
    "\n",
    "* holiday - Boolean - TRUE for holiday, FALSE for no holiday.\n",
    "\n",
    "* year - Integer - Year.\n",
    "\n",
    "* month - Integer - Month.\n",
    "\n",
    "* wday - Integer - Number of weekday. 1-7, starts on Monday.\n",
    "\n",
    "* weekend - Boolean - TRUE if weekend (Saturday or Sunday), FALSE if weekday.\n",
    "\n",
    "* long_holiday - Boolean - If holiday is more than 2 days. Here we added so if there's an holiday for an example on tuesday. Sat-Tue will be marked as 'long holiday' because Monday is a bridge day. TRUE for long holidays and FALSE for short holidays\n",
    "\n",
    "* schoolbreak - String - Name/description of school break. christmasbreak,\n",
    "nobreak, midwinterbreak springbreak\n",
    "summer_break\n",
    "\n",
    "* dayno - Integer - Number of the day in month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Specifying the data analytic question\n",
    "\n",
    " To identify the best cab company in which to make investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Defining the metric for success\n",
    "\n",
    "Being in position to single out the most profitable cab company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Understanding the Context\n",
    "\n",
    "XYZ is a private firm in US. Due to remarkable growth in the Cab Industry in last few years and multiple key players in the market, it is planning for an investment in Cab industry and as per their Go-to-Market(G2M) strategy they want to understand the market before taking final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Recording the Experimental Design\n",
    "\n",
    "* upload and read our csv files\n",
    "* clean our dataset\n",
    "* perfom EDA\n",
    "* build our models\n",
    "* challenge our solution\n",
    "* Evaluate their performance on the dataset at hand and then provide observations and recommendations on the suitability of each of the tested models on their appropriateness of solving the given problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Assessing the Relevance of the Data\n",
    "\n",
    "the data are rellevant as it has all data and values related to the cab and cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Loading and reading Our Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries\n",
    "#\n",
    "# load pandas\n",
    "import pandas as pd               # library for data manipulation and analysis\n",
    "#\n",
    "# load numpy\n",
    "import numpy as np                # library for performin scientific computations\n",
    "#\n",
    "# load matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt   # library for creating basic visualisations\n",
    "#\n",
    "# load Seaborn\n",
    "import seaborn as sns             # library for creating rich data visualisations\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #loading and reading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. loading and reading the datasets\n",
    "#\n",
    "#Cab_Data.csv – this file includes details of transaction for 2 cab companies\n",
    "cab_df = pd.read_csv(\"Cab_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. City.csv – this file contains list of US cities, their population and number of cab users\n",
    "city_df = pd.read_csv(\"City.csv\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Customer_ID.csv – this is a mapping table that contains a unique identifier which links the customer’s demographic details\n",
    "customer_df = pd.read_csv(\"Customer_ID.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Transaction_ID.csv – this is a mapping table that contains transaction to customer mapping and payment mode\n",
    "transaction_df = pd.read_csv (\"Transaction_ID.csv\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. US holidays  information\n",
    "holiday_df = pd.read_csv(\"us_holidays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### steps in EDA\n",
    "'''\n",
    "*  Description of the data\n",
    "*  Handling of the missing data\n",
    "*  Handling of outliers\n",
    "*  Understanding the relationhips and insights through plots\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDERSTANDING THE DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. UNDERSTANDING CAB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cab dataset shape and informatiom\n",
    "print(\"Number of  records: \",cab_df.shape[0])\n",
    "print(\"Number of variable: \",cab_df.shape[1] )\n",
    "print((\"***\")*15)\n",
    "cab_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: cab dataset has 359392 records and 7 varaibles(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the first 5 top rows\n",
    "cab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the last 5 bottom rows\n",
    "cab_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: The dateset is unifrom from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concise summary\n",
    "cab_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "* Here as you can notice the mean value is slightly less than the median value of each column. Median is represented by 50%(50th percentile) in the index column. \n",
    "This might signifies the presence of Outliers. \n",
    "\n",
    "  For example, a variable price charges is (423.443311)\t, which is lower than the median (386.360000)\n",
    "* There is notably a large difference between 75th %tile and max values of input variables “price charged”, ”cost of the trip”. This indicates that some values of these 2 variables lie much farther from the general range of values(upto 75th %tile) \n",
    "* Thus, the observations 1 and 2 suggest that there are extreme values i.e Outliers in our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary for non numerical values\n",
    "cab_df.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: yellow cab has the highest records in company variable  and New York city has the highest records in city records in cab dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the unique values\n",
    "print(\"company unique values:\",\"\\n\", cab_df.Company.unique())\n",
    "print((\"*****\")*17)\n",
    "print(\"cities:\",\"\\n\", cab_df.City.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 companies operating in different cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the original dataset to use for data cleaning\n",
    "cab_df1 = cab_df.copy()\n",
    "#\n",
    "#identifying which column has missing values\n",
    "cab_df1.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking mising values using visualization\n",
    "#\n",
    "#!pip install missingno\n",
    "import missingno as an\n",
    "#\n",
    "#Alternative way to detect missing values\n",
    "import missingno as an\n",
    "an.matrix(cab_df1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "print(\"Duplicates: \", cab_df1.duplicated().sum().any())\n",
    "#\n",
    "#checking the summary\n",
    "cab_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers for price charged columns\n",
    "cab_df1.boxplot(figsize=(10,5))\n",
    "plt.title(\"checking for outliers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is outlier in price cahrged variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a clear view of outliers for price charged column\n",
    "cab_df1.boxplot(figsize=(10,5), column=\"Price Charged\")\n",
    "plt.title(\"with for outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is ouliers in price charged variable, we will remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with outliers\n",
    "#computing the IQR\n",
    "q1 = cab_df1[\"Price Charged\"].quantile(0.25)\n",
    "q3 = cab_df1[\"Price Charged\"].quantile(0.75)\n",
    "iqr = q3-q1\n",
    "print(\"q1 :\" ,q1, \"\\n\", \"q3 :\" ,q3, \"\\n\",\"iqr :\", iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cab_df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers\n",
    "lower_outlier = cab_df1[\"Price Charged\"]< (q1-1.5*iqr)\n",
    "upper_outlier = cab_df1[\"Price Charged\"] > (q3+1.5*iqr)\n",
    "cab_df1[lower_outlier|upper_outlier] # this shows data_dfcab_df1 with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking median\n",
    "print(\"price charged variable mean is: \", cab_df1[\"Price Charged\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data_df without outliers\n",
    "cab_df2 = cab_df[~(lower_outlier|upper_outlier)]\n",
    "#\n",
    "#checking the outliers \n",
    "cab_df2.boxplot(figsize=(10,5), column=\"Price Charged\")\n",
    "plt.title(\"without for outliers\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: outliers has drastically reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking new summary\n",
    "cab_df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#computing prifit column\n",
    "cab_df1['Profit_Margin'] = (cab_df1[\"Price Charged\"]-cab_df1[\"Cost of Trip\"])\n",
    "cab_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the profit margin column\n",
    "cab_df2['Profit_Margin'] = (cab_df2['Price Charged']-cab_df2['Cost of Trip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing \"Date of Travel\" variable to datetime\n",
    "#\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "cab_df2['Travel_Date'] = datetime(1899,12,29) + cab_df2['Date of Travel'].map(dt.timedelta)\n",
    "#\n",
    "# removing unnessary \"Date of Travel colunm\n",
    "print(\"Date travel variable dropped\", cab_df2.drop(\"Date of Travel\", axis =1, inplace = True))\n",
    "#\n",
    "#checking the dataset\n",
    "cab_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting Travel date into days, months, and years\n",
    "\n",
    "cab_df2['Year'] = pd.DatetimeIndex(cab_df2['Travel_Date']).year\n",
    "cab_df2['Month'] = pd.DatetimeIndex(cab_df2['Travel_Date']).month\n",
    "cab_df2['Weekday'] = pd.DatetimeIndex(cab_df2['Travel_Date']).weekday\n",
    "cab_df2['Day'] = pd.DatetimeIndex(cab_df2['Travel_Date']).day\n",
    "#\n",
    "#checking the changes\n",
    "cab_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing variable names for readability\n",
    "#\n",
    "cab_df2.columns =cab_df2.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "print(\"cab dataset columns:\",\"\\n\", cab_df2.columns)\n",
    "\n",
    "#the final clean cab dataset\n",
    "cab_clean = cab_df2.copy()\n",
    "cab_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. UNDERSTANDING CITY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the top 5 rows\n",
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking 5 bottom rows\n",
    "city_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset is uniform from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#city dataset shape and variable datatype\n",
    "\n",
    "print(\"Number of  records: \",city_df.shape[0])\n",
    "print(\"Number of variable: \",city_df.shape[1] )\n",
    "print((\"***\")*15)\n",
    "city_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are 20 records and 3 variables\n",
    "* there is no null values and the datset comprises of 3 categorical variable. But population and users should be integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning city dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy to be used for data cleaning\n",
    "city_df1 = city_df.copy()\n",
    "\n",
    "#Removing \",\" between the numbers and changing the datatype\n",
    "city_df1[\"Population\"] = city_df1[\"Population\"].str.replace(\",\",\"\").astype(int)\n",
    "city_df1[\"Users\"] = city_df1[\"Users\"].str.replace(\",\",\"\").astype(int)\n",
    "#\n",
    "#confirming dataype changes\n",
    "print(\"datatypes\", \"\\n\", city_df1.dtypes)\n",
    "#\n",
    "#confirming the changes\n",
    "city_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By removing \",\", this  will help us in computation as well as change datetype from categorical to the correct datatype.\n",
    "* we now have 2 integer and 1 categorical datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "print(\"Null values :\", city_df1.isna().sum().any())\n",
    "#checking for duplicates\n",
    "print(\"duplicates :\", city_df1.duplicated().any())\n",
    "#\n",
    "#checking the price summary\n",
    "city_df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* population is 8405837\n",
    "\n",
    "* minimum cab users are 3643 and maximum user are 302149 pearsons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary for non numerical values\n",
    "city_df1.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Chicago IL city has the highest records in city dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers for city dataset\n",
    "city_df1.boxplot(figsize=(10,5))\n",
    "plt.title(\"Outlier Detection\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are outliers in both population and users variable however we will not remove them for EDA purpose as they look genuine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the colunms standard\n",
    "city_df1.columns =city_df1.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "#\n",
    "# final clean city dataset\n",
    "city_clean = city_df1. copy()\n",
    "#\n",
    "#preview\n",
    "city_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. UNDERSTANDING CUSTOMER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the first 5 rows\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 5 rows\n",
    "customer_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is unifrom from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customer dataset shape and variable datatype\n",
    "\n",
    "print(\"Number of  records: \",customer_df.shape[0])\n",
    "print(\"Number of variable: \",customer_df.shape[1] )\n",
    "print((\"***\")*15)\n",
    "customer_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset has 49171 records and 4 variables\n",
    "* There are 3 integer variables and 1 categorical variable.\n",
    "* dataset has a memory of 1.5+MB\n",
    "* There is a hind of no missing variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning customer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a copy of dataset for cleaning\n",
    "customer_df1 = customer_df.copy()\n",
    "#\n",
    "#checking missing values\n",
    "print(\"Null values :\", customer_df1.isnull().sum().any())\n",
    "#checking for duplicates\n",
    "print(\"duplicates :\",customer_df1.duplicated().sum().any())\n",
    "\n",
    "# checking consice summary\n",
    "customer_df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the minimum age of the customer is 18 years, and the maximum is 65 years old.\n",
    "* the mean age is 35.3 years.\n",
    "* the minimum income of the customers is  USD 2000  per month, and the maximum income is USD 35000 per month.\n",
    "* the mean income is USD 15015.6 per month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary for non numerical values\n",
    "customer_df.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Male clients top in number in customer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers\n",
    "customer_df1.boxplot(figsize=(10,5))\n",
    "plt.title(\"checking for outliers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking column name\n",
    "customer_df1.rename({\"Income (USD/Month)\":'Income'},axis=1, inplace = True)\n",
    "customer_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the colunms standard\n",
    "customer_df1.columns =customer_df1.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "#\n",
    "#final customer dataset\n",
    "customer_clean = customer_df1.copy()\n",
    "customer_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. understanding transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the top 5 rows\n",
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the bottom 5 rows\n",
    "transaction_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there's uniformity from top to the bottom of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape and datatype\n",
    "print(\"transaction dataset shape\" \"\\n\",transaction_df.shape)\n",
    "print((\"***\")*30)\n",
    "print (transaction_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are 440098 records and 3 variables.\n",
    "* dataset comprises of 3 integers and 1 categorical datatype variables.\n",
    "* this is a hind thate there is no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning for transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a copy of dataset for cleaning\n",
    "transaction_df1 = transaction_df.copy()\n",
    "#\n",
    "#checking missing values\n",
    "print(\"Null values :\", transaction_df1.isnull().sum().any())\n",
    "\n",
    "#checking for duplicates\n",
    "print(\"duplicates :\",transaction_df1.duplicated().sum().any())\n",
    "\n",
    "# checking consice summary\n",
    "transaction_df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary for non numerical values\n",
    "transaction_df1.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: card mode of payment leads in transaction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers\n",
    "transaction_df1.boxplot(figsize=(10,5))\n",
    "plt.title(\"transaction outlier check\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the colunms standard\n",
    "transaction_df1.columns =transaction_df1.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "print(\"transaction dataset columns:\", \"\\n\", transaction_df1.columns)\n",
    "#\n",
    "#final transaction dataset\n",
    "transaction_clean = transaction_df1.copy()\n",
    "transaction_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. UNDERSTANDING US HOLIDAYS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the top 5 rows\n",
    "holiday_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the bottom 5 rows\n",
    "holiday_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: the dataset values are unifrom from top to the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking shape and infomation\n",
    "print(\"Number of  records: \",holiday_df.shape[0])\n",
    "print(\"Number of variable: \",holiday_df.shape[1] )\n",
    "print((\"***\")*13)\n",
    "holiday_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "* the dataset comprises of 3288 records and 10 variables/columns\n",
    "* it has 3 boolan, 4 integers and 3 categorical variables\n",
    "* it is of 189.6+kB memories\n",
    "* there is no missing values.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary for non numerical values\n",
    "holiday_df.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: most of the clients used the cab not during the holidays and when the schools were in session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy for cleaning\n",
    "holiday_df1 = holiday_df.copy()\n",
    "#\n",
    "#checking duplicates\n",
    "print(\"duplicates: \", holiday_df1.duplicated().any())\n",
    "print(\"missing value: \", holiday_df1.isna().sum().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for ouliers\n",
    "holiday_df1.boxplot(figsize = (15,5))\n",
    "plt.title(\"outlier check in holiday dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: there is outliers in Holiday and long_holiday variables; however these are genuine thus  i will not remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing date variable to datetime\n",
    "holiday_df1['date'] = pd.to_datetime(holiday_df1['date'].str.strip(), format='%Y/%m/%d')\n",
    "#\n",
    "#creating weekend variable \n",
    "holiday_df1['Weekday'] = pd.DatetimeIndex(holiday_df1['date']).weekday\n",
    "#\n",
    "#and then dropping date variable\n",
    "holiday_df1.drop(columns = [\"date\", \"wday\"], axis =1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column names\n",
    "holiday_df1= holiday_df1.rename(columns={\"dayno\":\"Day\",\"holiday_name\": \"Holiday_Name\",\"holiday\":\"Holiday\", \n",
    "                            \"year\":\"Year\", \"month\": \"Month\", \"weekend\":\"Weekend\", \n",
    "                            \"long_holiday\": \"Long_Holiday\", \"school_break\":\"school_break\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting specific period needed for analysis\n",
    "holiday_df1 = holiday_df1.query('Year >= 2016 & Year <= 2018')\n",
    "\n",
    "#final dataset\n",
    "holiday_clean = holiday_df1.copy()\n",
    "holiday_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGING THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. merging cab and city dataset\n",
    "merged_df1 = pd.merge(cab_clean, city_clean, on='City')\n",
    "\n",
    "#check for null values\n",
    "print(\"Null values :\", merged_df1.isna().sum().any())\n",
    "\n",
    "#drop duplicates if any\n",
    "merged_df1= merged_df1.drop_duplicates()\n",
    "\n",
    "#merged dataset preview\n",
    "merged_df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.  merging merged df1 dataset with transaction dataset\n",
    "merged_df2 = pd.merge(merged_df1, transaction_clean, on='Transaction_ID')\n",
    "\n",
    "#check for null values\n",
    "print(\"Null values :\", merged_df2.isna().sum().any())\n",
    "\n",
    "#drop duplicates if any\n",
    "merged_df2= merged_df2.drop_duplicates()\n",
    "\n",
    "#checking the shape of the merged dataset\n",
    "print(\"Number of  records: \",merged_df2.shape[0])\n",
    "print(\"Number of variable: \",merged_df2.shape[1] )\n",
    "\n",
    "#merged dataset preview\n",
    "merged_df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.  merging merged df2 dataset with customer dataset\n",
    "merged_df3 = pd.merge(merged_df2, customer_clean, on='Customer_ID')\n",
    "\n",
    "#check for null values\n",
    "print(\"Null values :\", merged_df3.isna().sum().any())\n",
    "\n",
    "#drop duplicates if any\n",
    "merged_df3= merged_df3.drop_duplicates()\n",
    "\n",
    "#checking the shape of the merged dataset\n",
    "print(\"Number of  records: \",merged_df3.shape[0])\n",
    "print(\"Number of variable: \",merged_df3.shape[1] )\n",
    "#merged dataset preview\n",
    "merged_df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.  merging merged d3 dataset with holiday dataset\n",
    "merged_df4 = pd.merge(merged_df3, holiday_clean, on=['Year','Day','Month','Weekday'], how='left')\n",
    "\n",
    "#check for null values\n",
    "print(\"Null values :\", merged_df4.isna().sum().any())\n",
    "\n",
    "#drop duplicates if any\n",
    "merged_df4= merged_df4.drop_duplicates()\n",
    "#\n",
    "#dropping transaction id variable since it serve same purpose\n",
    "merged_df4.drop(['Transaction_ID'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "#checking the shape of the merged dataset\n",
    "print(\"Final dataset Number of  records: \",merged_df4.shape[0])\n",
    "print(\"Final dataset Number of variable: \",merged_df4.shape[1] )\n",
    "\n",
    "\n",
    "#making a copy of final marged dataset\n",
    "final_merge = merged_df4.copy()\n",
    "#merged dataset preview\n",
    "final_merge.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate analysis\n",
    "\n",
    "I will now perform univariate analysis. This is a type of analysis done only one variable. This type of analysis will be helpful in understanding the characteristics of each variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the columns for analysis\n",
    "final_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: profit margin variable distplot\n",
    "#\n",
    "plt.figure(figsize = (15, 5))\n",
    "sns.distplot(final_merge.Profit_Margin, bins=\"auto\", kde= True, color= \"r\")\n",
    "plt.title(\"profit margin distplot\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: The 'Profit_margin' variable is not normally distributed. It is skewed to the right(positive skew), this means the mean is greater than the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: Income variable distplot\n",
    "#\n",
    "plt.figure(figsize = (15, 5))\n",
    "sns.distplot(final_merge[\"Income\"], bins=\"auto\", kde= True, color= \"r\")\n",
    "plt.title(\"income distplot\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: This shows distribution of income, the density of the point are more for income USD/month ranging from  4000 to 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie plot indicating the Weekday ratio of the dataset\n",
    "#\n",
    "fig = px.pie(final_merge, values= None, names ='Company', hole=0.2)\n",
    "fig.update_traces(textinfo=\"label+percent\", insidetextfont= dict(color=\"white\"))\n",
    "fig.update_layout(legend = {\"itemclick\": False})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: yellow cab dominate the usage by 76.4% compared to it's rival. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie plot indicating the Weekday ratio of the dataset\n",
    "#\n",
    "fig = px.pie(final_merge, values= None, names ='Weekday', hole=0.2)\n",
    "fig.update_traces(textinfo=\"label+percent\", insidetextfont= dict(color=\"white\"))\n",
    "fig.update_layout(legend = {\"itemclick\": False})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: Note that monday = 0, Tuesday = 1, Wednesday = 2, Thursday = 3, Friday = 4, saturday = 5, and sunday = 6.\n",
    "* most of the customers prefer to use taxi on thursday(3) and friday(4), this is because this days near the weekend.\n",
    "* day 6(sunday) is the lowest, this is bacause it is a weekend and most of the customers prefer spending their time at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: gender  variable pie chart.\n",
    "#\n",
    "pie= px.pie(final_merge, names=\"Gender\", hole=0.2)\n",
    "pie.update_traces(textinfo=\"label+percent\", insidetextfont= dict(color=\"white\"))\n",
    "pie.update_layout(legend = {\"itemclick\": False})\n",
    "pie.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: there are more male customers at (57.2%) compared to female customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# univariate analysis: weekend variable bar chart\n",
    "barchart = px.bar(data_frame=final_merge,\n",
    "                  x=[\"False\", \"True\"],\n",
    "                  y= final_merge[\"Weekend\"].value_counts().sort_values(ascending=False).head())\n",
    "barchart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation:\n",
    "* Note: True =weekend  & False =Other days(weekdays)\n",
    "\n",
    "* customers use cab in weekdays more compared to the weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: the age bar plot\n",
    "final_merge[\"Age\"].hist(bins= 160, figsize=(12,10), color = \"brown\" )\n",
    "plt.title(\"Age plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation:the customers between the age of 18 to 40 use the cab the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis for customers below age of 40 years and those above 40 years\n",
    "#creating age dataframe\n",
    "Age_df = final_merge.groupby('Age').Customer_ID.count()\n",
    "\n",
    "#indexing\n",
    "Age_df1= [Age_df[Age_df.index<=40].values.sum(),Age_df[Age_df.index>40].values.sum()]\n",
    "    \n",
    "#reating lebels\n",
    "labels = 'Age below 40','Age above 40'\n",
    "Explode = [0,0.1] \n",
    "#\n",
    "#creating pie plot\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.pie(Age_df1, labels=labels, explode=Explode, autopct='%1.1f%%', startangle=45, colors=('green','brown'))\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.title('Age segment customer share')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: 73.2% of the customers below 40 years use the cab, this can be attributed to the fact that they have not yet acquired private means of transport yes. It might be because of flexibility of the cab service as well as being cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: mode of payment pie chart\n",
    "Explode = [0,0.1] \n",
    "plt.figure(figsize = (6, 6))\n",
    "final_merge.Payment_Mode.value_counts().plot(kind = 'pie', explode=Explode, autopct = '%0.1f%%', startangle = 45, colors = (\"green\", \"skyblue\"))\n",
    "plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title(\"Mode of payment pie chart\")\n",
    "plt.legend(title=\"mode of payment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: most of the 60% of the clients prefer card mode of payment, this can be attributed to the fact thate  it is same and most of the customers don't like walking along with hard cash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: weekday bar chart\n",
    "plt.figure(figsize = (10, 5))\n",
    "final_merge.Weekday.value_counts(ascending=False).plot(kind = 'bar', rot = 45, color = \"darkgreen\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.xlabel(\"Day of the week\")\n",
    "plt.title(\"weekday bar chart\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: the customers used the cab mostly on Thursday(3),Friday(4), and saturday(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis: weekday bar chart\n",
    "plt.figure(figsize = (10,8))\n",
    "final_merge.Holiday_Name.value_counts(ascending=False).plot(kind = 'bar', rot = 45, color = \"brown\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.xlabel(\"Holiday name\")\n",
    "plt.title(\"Holiday bar chart\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: there are more records of cab use on non holiday days, this might be attributed to use of cabs on working and school days. It is also because customers prefer sitting at home during the holidays.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # univariate analysis: mode of payment pie chart\n",
    "Explode = [0,0.1] \n",
    "plt.figure(figsize = (6, 6))\n",
    "final_merge.Holiday.value_counts().plot(kind = 'pie', explode=Explode, autopct = '%0.1f%%', startangle = 45, colors = (\"skyblue\", \"gray\"))\n",
    "plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title(\"Holiday pie chart\")\n",
    "plt.legend(title=\"Holiday\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: 96.7% of  respodent use tha cab on non holiday days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis\n",
    "\n",
    "I will now perform bivariate analysis, which is a type of analysis that involves two variables. The main objective is to understand the relationships between these two types of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biriate analysis, relationship between profit margin and years\n",
    "\n",
    "fig = px.pie(final_merge, values='Profit_Margin', names='Year', color=\"Company\", hole=0.3)\n",
    "fig.update_traces(textinfo=\"label+percent\", insidetextfont= dict(color=\"white\"))\n",
    "fig.update_layout(legend = {\"itemclick\": False})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biviate analysis: profit vs years\n",
    "profit_distribution=final_merge.groupby([final_merge.Year]).sum()\n",
    "profit_distribution.Profit_Margin.plot(figsize=(10,5), linewidth=2)\n",
    "plt.title('Profit vs year', fontsize=20)\n",
    "plt.xlabel('year', fontsize=10);\n",
    "plt.ylabel('profit', fontsize=10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: the above two analysis shows the same thing, profit was higher in 2017 at 37% and and was the same for year 2016 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate analysis: Company vs Gender\n",
    "plt.figure(figsize = (6, 6))\n",
    "sns.countplot(x = 'Company', hue = \"Gender\", data = final_merge, palette=\"inferno\")\n",
    "plt.title(\"Company vs Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "* yellow cab is prefered with both male and female customers compared to pink cab.\n",
    "* male uses both cabs more compared to female customers. this can be attributed to the fact that male travel alot compared to their counterparts.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate analysis: city vs company\n",
    "plt.figure(figsize = (6, 10))\n",
    "sns.countplot(y='City', data=final_merge, hue='Company', order=final_merge['City'].value_counts().sort_values(ascending=False).index, palette=\"plasma\")\n",
    "plt.title(\"city vs company\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obervation: \n",
    "* yellow cab has more presence in new york city, this can be attributed to the government rugulations where the yellow cab is allowed to pick and drop passangers anywhere in the city, and it is the one that have access to the airports.\n",
    "* yellow cab is leading in all cities except in Sandiago where pink cab is more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate analysis: city vs weekedn\n",
    "plt.figure(figsize = (6, 10))\n",
    "sns.countplot(y='City', data=final_merge, hue='Weekend', order=final_merge['City'].value_counts().sort_values(ascending=False).index, palette =\"magma\")\n",
    "plt.title(\"city vs weekend\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation:\n",
    "* in all cities, people prefer using the cab during weekday compared to weekend. this is because most of the people spend the weekend at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis: weekend vs Company\n",
    "plt.figure(figsize = (6, 6))\n",
    "sns.countplot(x = 'Weekday', hue = \"Company\", data = final_merge, palette=\"hls\")\n",
    "plt.title(\"Company vs weekend\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation:\n",
    "* both yellow and pink cabs are on high demand near the weekend on Thurday, Friday, and Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis: company Vs month\n",
    "plt.figure(figsize = (6, 6))\n",
    "sns.countplot(x = 'Month', hue = \"Company\", data = final_merge, palette=\"hls\")\n",
    "plt.title(\"Company vs Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "* customers use the cab more at the of the year, this can be attributed to people havening money they have been saving all year round, also some companies give bonuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis: company Vs month\n",
    "plt.figure(figsize = (10, 20))\n",
    "sns.countplot(x = 'Day', hue = \"Company\", data = final_merge, palette=\"hls\").plot(kind = 'bar',palette = \"hls\")\n",
    "plt.title(\"Company vs Month\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation:\n",
    "* yellow cab is used more than pink cab all month round. on the second day of the month, mid month 16th almost the end of the month customers use the cab more, this can attributed to pay check days thus they have money to spend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis: year vs Company\n",
    "plt.figure(figsize = (6, 6))\n",
    "sns.countplot(x = 'Year', hue = \"Company\", data = final_merge, palette=\"magma\")\n",
    "plt.title(\"Company vs year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: \n",
    "* customer used cabs in 2017 more compared to other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bivariate analysis: school break vs year\n",
    "plt.figure(figsize = (15, 6))\n",
    "sns.countplot(x = 'Year', hue = \"school_break\", data = final_merge, palette=\"hls\")\n",
    "plt.title(\"school break vs year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: \n",
    "* customers use cab more during school days followed by during summer, this is because most of students use cab to and fro schools and colleges. \n",
    "* In summer the weather is extremely hot that customers cannot walk for long distances.\n",
    "* customer use the cabs also durin chrismass holidays to make movement around easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate analysis\n",
    "\n",
    "I will now perform multivariate analysis. This is a type of analysis done on more than 2 variables. This type of analysis will be helpful in understanding the relationship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the correlation of numerical variable\n",
    "#\n",
    "#selecting numerical variable\n",
    "numeric_df = final_merge[['KM_Travelled','Price_Charged','Cost_of_Trip','Month','Year','Age','Income','Profit_Margin']]\n",
    "\n",
    "#checking correlation\n",
    "corr = numeric_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation: the above can be represented with heatmap as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.heatmap(corr, vmax = 8, linewidth=0.01, square = True,  annot=True, cmap= \"gist_heat\", linecolor=\"white\")\n",
    "plt.title(\"correlation betwen features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation:\n",
    "* There is  a strong positive correlation between price charges, kilometer travelled, cost of trip,  and profit margin.\n",
    "* there is a negative correlation between km travelled,age,income, and month etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **HYPOTHESIS TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing scipy  library and greatin a function to check years.\n",
    "from scipy import stats\n",
    "\n",
    "def t1_test(H0,H1,H2):\n",
    "    _, p = stats.f_oneway(H0.values, H1.values, H2.values)\n",
    "    p\n",
    "    if(p<0.05):\n",
    "        print(\"Reject the null hypothesis that there is no relationship (these are depedent variable)\")\n",
    "    else:\n",
    "        print(\"accept the null hypothesis that there is no relationship (these are indepedent variable)\")\n",
    "    \n",
    "    print(\"P value: \", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. checking on whether there is any difference on yellow cab customers in 3 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = final_merge[(final_merge.Company=='Yellow Cab')&(final_merge.Year==2016)].groupby('Month').Customer_ID.count()\n",
    "H1 = final_merge[(final_merge.Company=='Yellow Cab')&(final_merge.Year==2017)].groupby('Month').Customer_ID.count()\n",
    "H2 = final_merge[(final_merge.Company=='Yellow Cab')&(final_merge.Year==2018)].groupby('Month').Customer_ID.count()\n",
    "t1_test(H0,H1,H2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 way way hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library to use for hypothesis testing\n",
    "from scipy import stats\n",
    "\n",
    "def t_test(H0,H1):\n",
    "    _, p = stats.ttest_ind(H0.values, H1.values,equal_var=True)\n",
    "    if(p <0.05):\n",
    "        print(\"Reject the null hypothesis that there is no relationship (these are depedent variable)\")\n",
    "    else:\n",
    "        print(\"accept the null hypothesis that there is no relationship (these are indepedent variable)\")\n",
    "    \n",
    "    print(\" P value: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. checking whether there is adiffernce between pink cab profit margin and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = final_merge[(final_merge.Gender=='Female')&(final_merge.Company=='Pink Cab')].groupby('Customer_ID').Profit_Margin.mean()\n",
    "H1 = final_merge[(final_merge.Gender=='Male')&(final_merge.Company=='Pink Cab')].groupby('Customer_ID').Profit_Margin.mean()\n",
    "t_test(H0,H1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. checking whether there is adiffernce between cab, KM travelled  and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = final_merge[(final_merge.Gender=='Female')&(final_merge.Company== \"Yellow Cab\")].groupby('Customer_ID').KM_Travelled.mean()\n",
    "H1= final_merge[(final_merge.Gender=='Male')&(final_merge.Company== \"Yellow Cab\")].groupby('Customer_ID').KM_Travelled.mean()\n",
    "t_test(H0,H1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. checking whether there is adiffernce between weekends, profit margin and age below and above 40 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = final_merge[(final_merge.Age<=40)&(final_merge.Weekend==True)].groupby('Customer_ID').Profit_Margin.mean()\n",
    "H1 = final_merge[(final_merge.Age>40)&(final_merge.Weekend==False)].groupby('Customer_ID').Profit_Margin.mean()\n",
    "t_test(H0,H1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  5. checking on whether there is a difference in cab profit for Card and Cash payer customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = final_merge[(final_merge.Payment_Mode=='Cash')&(final_merge.Company)].groupby('Customer_ID').Profit_Margin.mean()\n",
    "H1 = final_merge[(final_merge.Payment_Mode=='Card')&(final_merge.Company)].groupby('Customer_ID').Profit_Margin.mean()\n",
    "t_test(H0,H1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "* pink cab has small market share acroo the cities but it is present in all major cities.\n",
    "* yellow cab has a giant share of the market especially in New york and it enjoys the preference by customers compared to pink cab.\n",
    "* Yellow cab makes a big profit when the travel short distance as comapred to long haul. it seems this is a perfect strategy since customer can board and stop at any place, besides they have access to all the major airports.\n",
    "* customers don't use cab service much on holidays, but there is a slight increase on use on long holiday like chrismass break.\n",
    "* customers prefer paying with the card as compared o the cash, this can be attributed to crdit card payment preferences among customers as a mode of payment. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **RECOMENDATIONN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Investor should go ahead and invest in yellow cab since it has a large-solid market, good strategy to attract customers as well versed on how to enjoy the dominance all year round.\n",
    "* cab can expand their market by targeting other big cities where yellow cab has less dominance.\n",
    "* yellow cab should continue with short distance strategy if they need to make more profits.\n",
    "* Government policies should favour pink cab if they need to expnd since most cities are saturated by the yellow cab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
